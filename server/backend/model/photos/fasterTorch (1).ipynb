{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMZKL6hwwA7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f6286799-2eb7-4fb4-c17d-8bde6fac43b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f72f16c3-3f65-4a8e-a829-9fe8cd049ec6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f72f16c3-3f65-4a8e-a829-9fe8cd049ec6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final_burn_dataset_for_colab.zip to final_burn_dataset_for_colab.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded= files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/final_burn_dataset_for_colab.zip'\n",
        "output_dir = '/content/' # התיקייה שבה הנתונים יחולצו\n",
        "\n",
        "print(f\"פותח את קובץ ה-ZIP: {zip_path}...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "print(\"הנתונים נחלצו בהצלחה ל- /content/final_burn_dataset/\")\n",
        "# לוודא שהנתיבים ש-Colab יצר נכונים\n",
        "if os.path.exists(os.path.join(output_dir, \"final_burn_dataset\", \"train\", \"train_images\")):\n",
        "    print(\"מבנה התיקיות תקין.\")\n",
        "else:\n",
        "    print(\"אזהרה: מבנה התיקיות שונה מהצפוי. אנא וודאי את הנתיבים.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-ZujCIN7xba",
        "outputId": "de9c0682-367a-4662-a8c4-52eb2abae3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "פותח את קובץ ה-ZIP: /content/final_burn_dataset_for_colab.zip...\n",
            "הנתונים נחלצו בהצלחה ל- /content/final_burn_dataset/\n",
            "מבנה התיקיות תקין.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install lxml  # לוודא ש-lxml מותקן לקריאת XMLs\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AVcDvIdA3cr",
        "outputId": "a262225e-5c7b-43ca-c35b-057a570b9a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Torch version: 2.5.1+cu121\n",
            "Torchvision version: 0.20.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "import warnings\n",
        "from torchvision import transforms as T\n",
        "\n",
        "# ייבוא עבור הערכת mAP\n",
        "from torchvision.models.detection.coco_utils import get_coco_api_from_dataset\n",
        "from torchvision.models.detection.coco_eval import CocoEvaluator\n",
        "\n",
        "# הסתרת אזהרות מיותרות מ-Pillow ו-UserWarning כלליות\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# --- 1. הגדרות גלובליות ---\n",
        "ROOT_DIR_TRAIN_IMAGES      = r\"/content/final_burn_dataset/train/train_images\"\n",
        "ROOT_DIR_TRAIN_ANNOTATIONS = r\"/content/final_burn_dataset/train/train_xmls\"\n",
        "ROOT_DIR_TEST_IMAGES       = r\"/content/final_burn_dataset/test/test_images\"\n",
        "ROOT_DIR_TEST_ANNOTATIONS  = r\"/content/final_burn_dataset/test/test_xmls\"  # ישמש כסט ולידציה\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"משתמש ב- DEVICE: {DEVICE}\")\n",
        "\n",
        "CLASS_MAP = {\n",
        "    '__background__': 0, # חובה עבור Faster R-CNN\n",
        "    'degree_1':       1,\n",
        "    'degree_2':       2,\n",
        "    'degree_3':       3\n",
        "}\n",
        "NUM_CLASSES = len(CLASS_MAP)  # = 4\n",
        "\n",
        "# --- 2. פונקציות עזר לטיפול בנתונים ---\n",
        "\n",
        "def get_transform(train):\n",
        "    if train:\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.RandomHorizontalFlip(0.5),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "            T.RandomAdjustSharpness(sharpness_factor=2, p=0.3),\n",
        "            T.RandomRotation(degrees=10, expand=False, fill=0), # סיבובים קלים. fill=0 לשחור, expand=False לא משנה גודל תמונה.\n",
        "        ])\n",
        "    else: # עבור ולידציה והסקה, רק המרה ל-Tensor\n",
        "        return T.Compose([ T.ToTensor() ])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    פונקציית עזר ל-DataLoader שמשלבת דוגמאות בודדות לבאצ'ים.\n",
        "    זה נחוץ כאשר גודל התמונות או מספר האובייקטים בהן משתנה.\n",
        "    \"\"\"\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# --- 3. CustomDataset לטעינת נתונים ---\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir_images, root_dir_annotations, transforms=None, class_map=None):\n",
        "        self.root_dir        = root_dir_images\n",
        "        self.annotations_dir = root_dir_annotations\n",
        "        self.transforms      = transforms\n",
        "        self.class_map       = class_map or CLASS_MAP\n",
        "\n",
        "        self.image_files_with_xmls = self._load_and_validate_image_xml_pairs()\n",
        "        # image_ids_int ישמש כ-image_id עבור COCOEvaluator\n",
        "        # זה חשוב שיהיה ייחודי ורציף (לרוב)\n",
        "        self.coco_image_ids = list(range(len(self.image_files_with_xmls)))\n",
        "\n",
        "        print(f\"בתיקייה {root_dir_images}: סה\\\"כ תמונות וביאורים נטענו בהצלחה: {len(self.image_files_with_xmls)}\")\n",
        "\n",
        "    def _load_and_validate_image_xml_pairs(self):\n",
        "        \"\"\"\n",
        "        טוען את כל זוגות קבצי התמונה וה-XML התואמים.\n",
        "        \"\"\"\n",
        "        valid_pairs = []\n",
        "        img_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
        "\n",
        "        xml_files = [f for f in os.listdir(self.annotations_dir) if f.endswith('.xml')]\n",
        "        xml_files.sort() # לוודא סדר קבוע ושחזור עקבי\n",
        "\n",
        "        for xml_file_name in xml_files:\n",
        "            base_name = os.path.splitext(xml_file_name)[0]\n",
        "\n",
        "            found_img_path = None\n",
        "            for ext in img_extensions:\n",
        "                temp_path = os.path.join(self.root_dir, base_name + ext)\n",
        "                if os.path.exists(temp_path):\n",
        "                    found_img_path = temp_path\n",
        "                    break\n",
        "\n",
        "            if found_img_path is None:\n",
        "                print(f\"אזהרה: תמונה {base_name} לא נמצאה עבור ביאור {xml_file_name}. מדלג על זוג זה.\")\n",
        "                continue\n",
        "\n",
        "            valid_pairs.append((found_img_path, os.path.join(self.annotations_dir, xml_file_name)))\n",
        "        return valid_pairs\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, xml_path = self.image_files_with_xmls[idx]\n",
        "        current_coco_image_id = self.coco_image_ids[idx] # ה-ID הייחודי עבור COCOEvaluator\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        width, height = img.size # קבלת מימדי התמונה המקורית\n",
        "\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes  = []\n",
        "        labels = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            if name not in self.class_map:\n",
        "                print(f\"אזהרה: מחלקה '{name}' לא ממופה ב-CLASS_MAP עבור תמונה {img_path}. מדלג על אובייקט זה.\")\n",
        "                continue\n",
        "\n",
        "            label_id = self.class_map[name]\n",
        "            bndbox   = obj.find('bndbox')\n",
        "\n",
        "            # קריאת קואורדינטות ואימותן\n",
        "            xmin = float(bndbox.find('xmin').text)\n",
        "            ymin = float(bndbox.find('ymin').text)\n",
        "            xmax = float(bndbox.find('xmax').text)\n",
        "            ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "            # וודא שהקואורדינטות תקינות (xmin < xmax, ymin < ymax)\n",
        "            # ושהן בטווח מימדי התמונה. קואורדינטות חייבות להיות חיוביות.\n",
        "            xmin = max(0.0, xmin)\n",
        "            ymin = max(0.0, ymin)\n",
        "            xmax = min(width, xmax)\n",
        "            ymax = min(height, ymax)\n",
        "\n",
        "            # אם התיבה לא תקינה לאחר התיקון, מדלגים עליה\n",
        "            if xmin >= xmax or ymin >= ymax:\n",
        "                print(f\"אזהרה: תיבה לא תקינה ({xmin},{ymin},{xmax},{ymax}) בתמונה {img_path}. מדלג.\")\n",
        "                continue\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(label_id)\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            # אם אין אובייקטים, יוצרים טנסורים ריקים המתאימים לפורמט\n",
        "            boxes  = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "            area   = torch.zeros((0,), dtype=torch.float32)\n",
        "        else:\n",
        "            boxes  = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            area   = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {\n",
        "            \"boxes\":    boxes,\n",
        "            \"labels\":   labels,\n",
        "            \"image_id\": torch.tensor([current_coco_image_id]), # ה-ID הייחודי עבור COCOEvaluator\n",
        "            \"area\":     area,\n",
        "            \"iscrowd\":  torch.zeros((len(boxes),), dtype=torch.int64) # כולם לא 'crowd'\n",
        "        }\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            # הטרנספורמציות מוחלות על התמונה.\n",
        "            # Faster R-CNN ב-torchvision מטפל באופן פנימי בשינויי קואורדינטות התיבות\n",
        "            # כתוצאה מטרנספורמציות כמו ToTensor.\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files_with_xmls)\n",
        "\n",
        "# --- 4. הגדרת המודל ---\n",
        "def create_fasterrcnn_model(num_classes):\n",
        "    \"\"\"\n",
        "    יוצר מודל Faster R-CNN מאומן מראש על COCO.\n",
        "    ומתאים אותו למספר המחלקות הספציפי שלנו.\n",
        "    \"\"\"\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
        "        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1\n",
        "    )\n",
        "\n",
        "    # מחליף את ראש החיזוי של המודל כדי להתאים למספר המחלקות החדש שלנו\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
        "        in_features, num_classes\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 5. פונקציות אימון והערכה ---\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    \"\"\"\n",
        "    מבצע אימון עבור אפוק אחד.\n",
        "    \"\"\"\n",
        "    model.train() # מעביר את המודל למצב אימון (מאפשר עדכון משקלים)\n",
        "    total_loss = 0\n",
        "    for i, (images, targets) in enumerate(data_loader):\n",
        "        images  = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets) # המודל מחזיר מילון הפסדים\n",
        "        losses    = sum(loss for loss in loss_dict.values()) # סוכם את כל סוגי ההפסדים\n",
        "\n",
        "        optimizer.zero_grad() # מאפס את הגרדיאנטים\n",
        "        losses.backward()     # מחשב גרדיאנטים אחורה\n",
        "        optimizer.step()      # מעדכן את משקלי המודל\n",
        "\n",
        "        total_loss += losses.item()\n",
        "        if i % 10 == 0: # מדפיס התקדמות כל 10 איטרציות\n",
        "            loss_strings = \", \".join([f\"{k}: {v.item():.4f}\" for k, v in loss_dict.items()])\n",
        "            print(f\"Epoch: {epoch}, Iteration: {i}/{len(data_loader)}, Total Loss: {losses.item():.4f} ({loss_strings})\")\n",
        "    return total_loss / len(data_loader) # ממוצע ההפסד לאפוק\n",
        "\n",
        "def evaluate(model, data_loader, device, coco_evaluator):\n",
        "    \"\"\"\n",
        "    מבצע הערכה על סט הוולידציה ומחשב מדדי mAP באמצעות COCOEvaluator.\n",
        "    \"\"\"\n",
        "    model.eval() # המודל חייב להיות במצב הערכה כדי לקבל תחזיות (לא לעדכן משקלים)\n",
        "    print(\"מבצע הערכה על סט הבדיקה (mAP)...\")\n",
        "\n",
        "    coco_evaluator.reset() # איפוס ה-evaluator לפני כל הערכה חדשה\n",
        "\n",
        "    with torch.no_grad(): # אין צורך לחשב גרדיאנטים בהערכה\n",
        "        for i, (images, targets) in enumerate(data_loader):\n",
        "            images  = list(image.to(device) for image in images)\n",
        "\n",
        "            # targets חייבים להיות ב-CPU עבור COCOEvaluator\n",
        "            targets_cpu = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
        "\n",
        "            outputs = model(images) # המודל במצב eval מחזיר תחזיות\n",
        "\n",
        "            # מעבירים את התחזיות ל-CPU עבור COCOEvaluator\n",
        "            outputs = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n",
        "\n",
        "            # התאמת הפורמט ל-COCOEvaluator\n",
        "            # הוא מצפה למילון בו המפתח הוא image_id (מספר שלם) והערך הוא מילון התחזיות\n",
        "            # השתמש ב-target[\"image_id\"].item() כדי לוודא קבלת ערך סקלרי שלם\n",
        "            res = {target[\"image_id\"].item(): output for target, output in zip(targets_cpu, outputs)}\n",
        "            coco_evaluator.update(res)\n",
        "\n",
        "            if i % 50 == 0: # מדפיס התקדמות כל 50 באצ'ים\n",
        "                print(f\"Eval Batch {i}/{len(data_loader)}\")\n",
        "\n",
        "    # צבירת תוצאות מכל התמונות וסיכום\n",
        "    coco_evaluator.accumulate()\n",
        "    coco_evaluator.summarize()\n",
        "\n",
        "    # ה-mAP הכללי (AP@[IoU=0.50:0.05:0.95|area=all|maxDets=100]) הוא המדד הראשון (אינדקס 0)\n",
        "    # בטבלת הסטטיסטיקות של COCO. זהו ה-mAP הממוצע על פני ספי IoU רבים.\n",
        "    overall_mAP = coco_evaluator.coco_eval['bbox'].stats[0]\n",
        "    return overall_mAP\n",
        "\n",
        "# --- 6. מחלקת EarlyStopping ---\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0, mode='min'):\n",
        "        self.patience    = patience    # מספר אפוקס לחכות לפני עצירה\n",
        "        self.min_delta   = min_delta   # שינוי מינימלי במדד כדי שייחשב שיפור\n",
        "        self.counter     = 0           # מונה אפוקס ללא שיפור\n",
        "        self.best_metric = None        # המדד הטוב ביותר שנצפה עד כה\n",
        "        self.early_stop  = False       # דגל לעצירה מוקדמת\n",
        "        self.mode        = mode        # 'min' (עבור Loss) או 'max' (עבור mAP)\n",
        "\n",
        "        if self.mode not in ['min', 'max']:\n",
        "            raise ValueError(\"mode חייב להיות 'min' או 'max'\")\n",
        "\n",
        "    def step(self, current_metric):\n",
        "        if self.best_metric is None: # אם זו הפעם הראשונה\n",
        "            self.best_metric = current_metric\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min': # למדדים שככל שפחות טוב יותר (כמו Loss)\n",
        "            if current_metric < self.best_metric - self.min_delta:\n",
        "                print(f\"מדד השתפר מ-{self.best_metric:.4f} ל-{current_metric:.4f}. איפוס מונה.\")\n",
        "                self.best_metric = current_metric\n",
        "                self.counter     = 0\n",
        "                return False\n",
        "            else:\n",
        "                self.counter += 1\n",
        "                print(f\"EarlyStopping counter: {self.counter} מתוך {self.patience} (מדד לא השתפר מ-{self.best_metric:.4f})\")\n",
        "                if self.counter >= self.patience:\n",
        "                    self.early_stop = True\n",
        "                    return True\n",
        "                return False\n",
        "        elif self.mode == 'max': # למדדים שככל שיותר טוב יותר (כמו mAP)\n",
        "            if current_metric > self.best_metric + self.min_delta:\n",
        "                print(f\"מדד השתפר מ-{self.best_metric:.4f} ל-{current_metric:.4f}. איפוס מונה.\")\n",
        "                self.best_metric = current_metric\n",
        "                self.counter     = 0\n",
        "                return False\n",
        "            else:\n",
        "                self.counter += 1\n",
        "                print(f\"EarlyStopping counter: {self.counter} מתוך {self.patience} (מדד לא השתפר מ-{self.best_metric:.4f})\")\n",
        "                if self.counter >= self.patience:\n",
        "                    self.early_stop = True\n",
        "                    return True\n",
        "                return False\n",
        "        return False # Fallback במקרה לא צפוי\n",
        "\n",
        "# --- 7. פונקציית MAIN להרצת תהליך האימון ובהסקה ---\n",
        "def main():\n",
        "    # טעינת נתוני אימון\n",
        "    print(\"טוען נתוני אימון...\")\n",
        "    dataset_train = CustomDataset(\n",
        "        root_dir_images=ROOT_DIR_TRAIN_IMAGES,\n",
        "        root_dir_annotations=ROOT_DIR_TRAIN_ANNOTATIONS,\n",
        "        transforms=get_transform(train=True),\n",
        "        class_map=CLASS_MAP\n",
        "    )\n",
        "\n",
        "    # טעינת נתוני ולידציה (ה-test directory שלנו)\n",
        "    print(\"טוען נתוני בדיקה (ולידציה)...\")\n",
        "    dataset_val = CustomDataset(\n",
        "        root_dir_images=ROOT_DIR_TEST_IMAGES,\n",
        "        root_dir_annotations=ROOT_DIR_TEST_ANNOTATIONS,\n",
        "        transforms=get_transform(train=False),\n",
        "        class_map=CLASS_MAP\n",
        "    )\n",
        "\n",
        "    # יצירת DataLoaders\n",
        "    data_loader_train = DataLoader(\n",
        "        dataset_train, batch_size=4, shuffle=True,\n",
        "        num_workers=2, collate_fn=collate_fn\n",
        "    )\n",
        "    data_loader_val = DataLoader(\n",
        "        dataset_val, batch_size=4, shuffle=False,\n",
        "        num_workers=2, collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    # הכנת כלי הערכת COCO לחישוב mAP\n",
        "    # `get_coco_api_from_dataset` יוצר אובייקט COCO-style מתוך ה-Dataset\n",
        "    # הוא ישתמש ב-image_id שהוגדר ב-CustomDataset\n",
        "    coco_dataset_val = get_coco_api_from_dataset(data_loader_val.dataset)\n",
        "    iou_types = [\"bbox\"] # עבור זיהוי אובייקטים אנו מעוניינים ב-Bounding Box IOU\n",
        "    coco_evaluator = CocoEvaluator(coco_dataset_val, iou_types)\n",
        "\n",
        "\n",
        "    # יצירת המודל והעברתו ל-DEVICE\n",
        "    print(\"יוצר מודל Faster R-CNN...\")\n",
        "    model = create_fasterrcnn_model(NUM_CLASSES)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # הגדרת אופטימייזר ולומד קצב (AdamW ו-ReduceLROnPlateau)\n",
        "    params    = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(params, lr=0.001, weight_decay=0.0005) # AdamW עם קצב למידה ו-weight_decay\n",
        "\n",
        "    # ReduceLROnPlateau מוריד את קצב הלמידה כשמדד הוולידציה (mAP) מפסיק להשתפר\n",
        "    lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    # הגדרת EarlyStopping ומשתנה לשמירת המודל הטוב ביותר (עודכן ל-mAP)\n",
        "    early_stopping  = EarlyStopping(patience=5, min_delta=0.001, mode='max')\n",
        "    NUM_EPOCHS      = 30 # מספר אפוקס מקסימלי לאימון\n",
        "    best_val_mAP    = float('-inf') # אתחול mAP הטוב ביותר כמינוס אינסוף (רוצים למקסם אותו)\n",
        "    best_model_path = \"best_fasterrcnn_model.pth\" # נתיב לשמירת המודל הטוב ביותר\n",
        "\n",
        "    # לולאת אימון + ולידציה\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        print(f\"\\n---- אפוק {epoch} ----\")\n",
        "        train_loss = train_one_epoch(model, optimizer, data_loader_train, DEVICE, epoch)\n",
        "        print(f\"איבוד באימון ממוצע (Epoch {epoch}): {train_loss:.4f}\")\n",
        "\n",
        "        # ביצוע הערכה וקבלת mAP בוולידציה\n",
        "        val_mAP = evaluate(model, data_loader_val, DEVICE, coco_evaluator)\n",
        "        print(f\"mAP בוולידציה (Epoch {epoch}): {val_mAP:.4f}\")\n",
        "\n",
        "        # עדכון לומד קצב הלמידה בהתבסס על mAP הוולידציה\n",
        "        lr_scheduler.step(val_mAP)\n",
        "\n",
        "        # שמירת המודל הטוב ביותר (רק אם ה-mAP השתפר)\n",
        "        if val_mAP > best_val_mAP:\n",
        "            print(f\"שומר מודל טוב יותר! mAP ולידציה עלה מ-{best_val_mAP:.4f} ל-{val_mAP:.4f}\")\n",
        "            best_val_mAP = val_mAP\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        # בדיקת תנאי עצירה מוקדמת\n",
        "        if early_stopping.step(val_mAP):\n",
        "            print(f\"עצירת אימון מוקדמת באפוק {epoch} עקב חוסר שיפור ב-mAP ולידציה\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nאימון הושלם. המודל הטוב ביותר נשמר ב-{best_model_path}\")\n",
        "\n",
        "    # --- שלב הסקה על תמונה מסט הוולידציה (דוגמה אקראית) ---\n",
        "    print(\"\\n--- מבצע הסקה על תמונת בדיקה אקראית מסט הוולידציה ---\")\n",
        "\n",
        "    # טוען את המודל המאומן הטוב ביותר\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval() # מעביר למצב הערכה\n",
        "\n",
        "    def visualize_and_infer(model, image_path, class_map, score_threshold=0.7):\n",
        "        \"\"\"\n",
        "        מבצע הסקה על תמונה בודדת ומציג את הזיהויים.\n",
        "        \"\"\"\n",
        "        rev_class_map = {v: k for k, v in class_map.items()} # מפה הפוכה לתוויות\n",
        "        img_orig = Image.open(image_path).convert(\"RGB\")\n",
        "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "        img_tensor = transform(img_orig).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad(): # אין צורך בחישוב גרדיאנטים בהסקה\n",
        "            prediction = model([img_tensor])\n",
        "\n",
        "        # חילוץ תוצאות: תיבות, תוויות וציוני ביטחון\n",
        "        boxes  = prediction[0]['boxes'].cpu().numpy()\n",
        "        labels = prediction[0]['labels'].cpu().numpy()\n",
        "        scores = prediction[0]['scores'].cpu().numpy()\n",
        "\n",
        "        draw = ImageDraw.Draw(img_orig)\n",
        "        # ניסיון לטעון גופן נפוץ בקולאב, או גופן ברירת מחדל\n",
        "        font_path = \"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\"\n",
        "        try:\n",
        "            if os.path.exists(font_path):\n",
        "                font = ImageFont.truetype(font_path, 20)\n",
        "            else:\n",
        "                font = ImageFont.load_default()\n",
        "        except Exception:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        detected_objects = []\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            # מציג רק זיהויים מעל סף הציון הנתון ולא רקע\n",
        "            if score > score_threshold and rev_class_map.get(label) != '__background__':\n",
        "                x_min, y_min, x_max, y_max = box.astype(int)\n",
        "                label_name = rev_class_map.get(label, \"Unknown\")\n",
        "\n",
        "                draw.rectangle([(x_min, y_min), (x_max, y_max)], outline=\"red\", width=3)\n",
        "                text_to_display = f\"{label_name}: {score:.2f}\"\n",
        "\n",
        "                # חישוב גודל הטקסט כדי לצייר רקע מתאים\n",
        "                try: # לגרסאות חדשות של Pillow\n",
        "                    bbox_text = draw.textbbox((x_min, y_min), text_to_display, font=font)\n",
        "                    text_width  = bbox_text[2] - bbox_text[0]\n",
        "                    text_height = bbox_text[3] - bbox_text[1]\n",
        "                except AttributeError: # לגרסאות ישנות יותר של Pillow\n",
        "                    text_width, text_height = draw.textsize(text_to_display, font=font)\n",
        "\n",
        "                # הוספת מרווח קטן לתיבת הטקסט\n",
        "                draw.rectangle([(x_min, y_min), (x_min + text_width + 4, y_min + text_height + 4)], fill=\"white\")\n",
        "                draw.text((x_min + 2, y_min + 2), text_to_display, fill=\"black\", font=font)\n",
        "\n",
        "                detected_objects.append({\n",
        "                    \"label\": label_name,\n",
        "                    \"score\": float(score),\n",
        "                    \"box\": [int(x_min), int(y_min), int(x_max), int(y_max)]\n",
        "                })\n",
        "\n",
        "        output_filename   = os.path.basename(image_path).split('.')[0] + \"_detected.jpg\"\n",
        "        output_image_path = os.path.join(\"/content/\", output_filename) # שומר בתיקיית ה-root של קולאב\n",
        "        img_orig.save(output_image_path)\n",
        "        print(f\"התמונה עם הזיהויים נשמרה ב: {output_image_path}\")\n",
        "\n",
        "        return detected_objects\n",
        "\n",
        "    # בודקים אם יש תמונות בסט הוולידציה לביצוע הסקה לדוגמה\n",
        "    if dataset_val.image_files_with_xmls:\n",
        "        random_idx = np.random.randint(0, len(dataset_val.image_files_with_xmls))\n",
        "        # קבלת נתיב התמונה מתוך הרשימה שנשמרה ב-dataset_val\n",
        "        example_image_path = dataset_val.image_files_with_xmls[random_idx][0]\n",
        "\n",
        "        if example_image_path:\n",
        "            print(f\"מבצע הסקה על התמונה: {example_image_path}\")\n",
        "            # סף הציון עבור ההסקה הסופית - ניתן לשנות\n",
        "            detections = visualize_and_infer(model, example_image_path, CLASS_MAP, score_threshold=0.7)\n",
        "            if detections:\n",
        "                print(\"אובייקטים שזוהו:\")\n",
        "                for det in detections:\n",
        "                    print(f\"    מחלקה: {det['label']}, ציון: {det['score']:.2f}, תיבה: {det['box']}\")\n",
        "            else:\n",
        "                print(\"לא זוהו אובייקטים בסף הציון הנתון.\")\n",
        "        else:\n",
        "            print(\"שגיאה: לא נמצאה תמונה לדוגמה בתיקיית הוולידציה.\")\n",
        "    else:\n",
        "        print(\"אין תמונות בסט הוולידציה לביצוע הסקה.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "IzodMxkm_51a",
        "outputId": "62c7e5dd-5307-495c-f43d-a4b9723cdcec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision.models.detection.coco_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-44271eaa0f81>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ייבוא עבור הערכת mAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco_eval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.models.detection.coco_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_images=5, score_threshold=0.5):\n",
        "    model.eval()\n",
        "    for idx in range(num_images):\n",
        "        img, target = dataset[idx]\n",
        "        img_tensor = img.to(device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)[0]\n",
        "\n",
        "        img_np = img.permute(1, 2, 0).cpu().numpy()\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(img_np)\n",
        "        ax = plt.gca()\n",
        "\n",
        "        # ניבויים\n",
        "        for box, label, score in zip(output['boxes'], output['labels'], output['scores']):\n",
        "            if score < score_threshold:\n",
        "                continue\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            class_name = list(CLASS_MAP.keys())[list(CLASS_MAP.values()).index(label.item())]\n",
        "            ax.text(xmin, ymin - 5, f\"{class_name} {score:.2f}\", color='white',\n",
        "                    bbox=dict(facecolor='red', alpha=0.5))\n",
        "\n",
        "        # תיבות אמת (GT)\n",
        "        for box, label in zip(target['boxes'], target['labels']):\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                     linewidth=1.5, edgecolor='green', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            class_name = list(CLASS_MAP.keys())[list(CLASS_MAP.values()).index(label.item())]\n",
        "            ax.text(xmin, ymax + 10, f\"{class_name} (GT)\", color='green',\n",
        "                    bbox=dict(facecolor='black', alpha=0.3))\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Image {idx+1} Predictions (red) and GT (green)\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "0yihHtuY0KFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "import warnings\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection.coco_utils import get_coco_api_from_dataset\n",
        "from torchvision.models.detection.coco_eval import CocoEvaluator\n",
        "\n",
        "#  אזהרות מיותרות מ-Pillow\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL\")\n",
        "\n",
        "ROOT_DIR_TRAIN_IMAGES      = r\"/content/final_burn_dataset/train/train_images\"\n",
        "ROOT_DIR_TRAIN_ANNOTATIONS = r\"/content/final_burn_dataset/train/train_xmls\"\n",
        "ROOT_DIR_TEST_IMAGES       = r\"/content/final_burn_dataset/test/test_images\"\n",
        "ROOT_DIR_TEST_ANNOTATIONS  = r\"/content/final_burn_dataset/test/test_xmls\"  # ישמש כסט ולידציה\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"משתמש ב- DEVICE: {DEVICE}\")\n",
        "\n",
        "CLASS_MAP = {\n",
        "    '__background__': 0,\n",
        "    'degree_1':       1,\n",
        "    'degree_2':       2,\n",
        "    'degree_3':       3\n",
        "}\n",
        "NUM_CLASSES = len(CLASS_MAP)  # = 4\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    if train:\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.RandomHorizontalFlip(0.5),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "            T.RandomAdjustSharpness(sharpness_factor=2, p=0.3),\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([ T.ToTensor() ])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir_images, root_dir_annotations, transforms=None, class_map=None):\n",
        "        self.root_dir        = root_dir_images\n",
        "        self.annotations_dir = root_dir_annotations\n",
        "        self.transforms      = transforms\n",
        "        self.class_map       = class_map or CLASS_MAP\n",
        "\n",
        "        self.image_ids = self._load_and_validate_image_ids()\n",
        "        print(f\"בתיקייה {root_dir_images}: סה\\\"כ תמונות וביאורים נטענו בהצלחה: {len(self.image_ids)}\")\n",
        "\n",
        "    def _load_and_validate_image_ids(self):\n",
        "        image_ids = []\n",
        "        xml_files = [f for f in os.listdir(self.annotations_dir) if f.endswith('.xml')]\n",
        "\n",
        "        for xml_file_name in xml_files:\n",
        "            base_name = os.path.splitext(xml_file_name)[0]\n",
        "\n",
        "            found_img_path = None\n",
        "            for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:\n",
        "                temp_path = os.path.join(self.root_dir, base_name + ext)\n",
        "                if os.path.exists(temp_path):\n",
        "                    found_img_path = temp_path\n",
        "                    break\n",
        "\n",
        "            if found_img_path is None:\n",
        "                print(f\"אזהרה: תמונה {base_name} לא נמצאה עבור ביאור {xml_file_name}. מדלג על זוג זה.\")\n",
        "                continue\n",
        "\n",
        "            image_ids.append(base_name)\n",
        "        return image_ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id_base = self.image_ids[idx]\n",
        "\n",
        "        img_path = None\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:\n",
        "            temp_path = os.path.join(self.root_dir, img_id_base + ext)\n",
        "            if os.path.exists(temp_path):\n",
        "                img_path = temp_path\n",
        "                break\n",
        "\n",
        "        if img_path is None:\n",
        "            raise FileNotFoundError(f\"קובץ תמונה לא נמצא עבור {img_id_base} עם אף סיומת נפוצה.\")\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        xml_path = os.path.join(self.annotations_dir, img_id_base + '.xml')\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes  = []\n",
        "        labels = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            if name not in self.class_map:\n",
        "                print(f\"אזהרה: מחלקה '{name}' לא ממופה ב-CLASS_MAP עבור תמונה {img_id_base}. מדלג על אובייקט זה.\")\n",
        "                continue\n",
        "\n",
        "            label_id = self.class_map[name]\n",
        "            bndbox   = obj.find('bndbox')\n",
        "            xmin = float(bndbox.find('xmin').text)\n",
        "            ymin = float(bndbox.find('ymin').text)\n",
        "            xmax = float(bndbox.find('xmax').text)\n",
        "            ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(label_id)\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            boxes  = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "        else:\n",
        "            boxes  = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\":    boxes,\n",
        "            \"labels\":   labels,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "            \"area\":     (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "                        if len(boxes) > 0\n",
        "                        else torch.zeros((0,), dtype=torch.float32),\n",
        "            \"iscrowd\":  torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "def create_fasterrcnn_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
        "        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1\n",
        "    )\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
        "        in_features, num_classes\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (images, targets) in enumerate(data_loader):\n",
        "        images  = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses    = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch: {epoch}, Iteration: {i}/{len(data_loader)}, Loss: {losses.item():.4f}\")\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    #  המודל למצב אימון באופן זמני כדי לקבל את מילון ההפסדים\n",
        "    model.train()\n",
        "    print(\"מבצע הערכה על סט הבדיקה...\")\n",
        "    eval_losses = []\n",
        "    with torch.no_grad(): # לא צריך גרדיאנטים להערכה\n",
        "        for i, (images, targets) in enumerate(data_loader):\n",
        "            images  = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses    = sum(loss for loss in loss_dict.values())\n",
        "            eval_losses.append(losses.item())\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                print(f\"Eval Batch {i}/{len(data_loader)}, Loss: {losses.item():.4f}\")\n",
        "\n",
        "    avg_eval_loss = np.mean(eval_losses) if eval_losses else 0\n",
        "    print(f\"הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: {avg_eval_loss:.4f}\")\n",
        "\n",
        "    #  לאחר חישוב הפסד הוולידציה\n",
        "    model.eval()\n",
        "    return avg_eval_loss\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        self.patience   = patience\n",
        "        self.min_delta  = min_delta\n",
        "        self.counter    = 0\n",
        "        self.best_loss  = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            return False\n",
        "\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter   = 0\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            print(f\"EarlyStopping counter: {self.counter} מתוך {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "def main():\n",
        "    print(\"טוען נתוני אימון\")\n",
        "    dataset_train = CustomDataset(\n",
        "        root_dir_images=ROOT_DIR_TRAIN_IMAGES,\n",
        "        root_dir_annotations=ROOT_DIR_TRAIN_ANNOTATIONS,\n",
        "        transforms=get_transform(train=True),\n",
        "        class_map=CLASS_MAP\n",
        "    )\n",
        "\n",
        "    print(\"טוען נתוני בדיקה\")\n",
        "    dataset_val = CustomDataset(\n",
        "        root_dir_images=ROOT_DIR_TEST_IMAGES,\n",
        "        root_dir_annotations=ROOT_DIR_TEST_ANNOTATIONS,\n",
        "        transforms=get_transform(train=False),\n",
        "        class_map=CLASS_MAP\n",
        "    )\n",
        "\n",
        "    data_loader_train = DataLoader(\n",
        "        dataset_train, batch_size=4, shuffle=True,\n",
        "        num_workers=2, collate_fn=collate_fn\n",
        "    )\n",
        "    data_loader_val = DataLoader(\n",
        "        dataset_val, batch_size=4, shuffle=False,\n",
        "        num_workers=2, collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    print(\"יוצר מודל\")\n",
        "    model = create_fasterrcnn_model(NUM_CLASSES)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # הגדרת אופטימייזר ולומד קצב\n",
        "    params    = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    lr_scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "    early_stopping  = EarlyStopping(patience=5, min_delta=0.001)\n",
        "    NUM_EPOCHS      = 30\n",
        "    best_val_loss   = float('inf')\n",
        "    best_model_path = \"best_fasterrcnn_model.pth\"\n",
        "\n",
        "    # לולאת אימון + ולידציה\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        print(f\"\\n---- אפוק {epoch} ----\")\n",
        "        train_loss = train_one_epoch(model, optimizer, data_loader_train, DEVICE, epoch)\n",
        "        print(f\"איבוד באימון (Epoch {epoch}): {train_loss:.4f}\")\n",
        "\n",
        "        val_loss = evaluate(model, data_loader_val, DEVICE)\n",
        "        print(f\"איבוד ולידציה (Epoch {epoch}): {val_loss:.4f}\")\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # שמירת המודל הטוב ביותר לפי ולידציה\n",
        "        if val_loss < best_val_loss:\n",
        "            print(f\"שומר מודל טוב יותר! איבוד ולידציה ירד מ-{best_val_loss:.4f} ל-{val_loss:.4f}\")\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        # בדיקת EarlyStopping\n",
        "        if early_stopping.step(val_loss):\n",
        "            print(f\"עצירת אימון מוקדמת באפוק {epoch} עקב חוסר שיפור באיבוד ולידציה\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nאימון הושלם. המודל הטוב ביותר נשמר ב-{best_model_path}\")\n",
        "\n",
        "    # שלב הסקה על תמונה מסט הוולידציה (דוגמה אקראית)\n",
        "    print(\"\\n--- מבצע הסקה על תמונת בדיקה אקראית מסט הוולידציה ---\")\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    def visualize_and_infer(model, image_path, class_map, score_threshold=0.7):\n",
        "        rev_class_map = {v: k for k, v in class_map.items()}\n",
        "        img_orig = Image.open(image_path).convert(\"RGB\")\n",
        "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "        img_tensor = transform(img_orig).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model([img_tensor])\n",
        "\n",
        "        boxes  = prediction[0]['boxes'].cpu().numpy()\n",
        "        labels = prediction[0]['labels'].cpu().numpy()\n",
        "        scores = prediction[0]['scores'].cpu().numpy()\n",
        "\n",
        "        draw = ImageDraw.Draw(img_orig)\n",
        "        font_path = \"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\"\n",
        "        try:\n",
        "            if not os.path.exists(font_path):\n",
        "                font = ImageFont.load_default()\n",
        "            else:\n",
        "                font = ImageFont.truetype(font_path, 20)\n",
        "        except Exception:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        detected_objects = []\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            if score > score_threshold and rev_class_map.get(label) != '__background__':\n",
        "                x_min, y_min, x_max, y_max = box.astype(int)\n",
        "                label_name = rev_class_map.get(label, \"Unknown\")\n",
        "\n",
        "                draw.rectangle([(x_min, y_min), (x_max, y_max)], outline=\"red\", width=3)\n",
        "                text_to_display = f\"{label_name}: {score:.2f}\"\n",
        "                bbox_text = draw.textbbox((x_min, y_min), text_to_display, font=font)\n",
        "                text_width  = bbox_text[2] - bbox_text[0]\n",
        "                text_height = bbox_text[3] - bbox_text[1]\n",
        "                draw.rectangle([(x_min, y_min), (x_min + text_width, y_min + text_height)], fill=\"white\")\n",
        "                draw.text((x_min, y_min), text_to_display, fill=\"black\", font=font)\n",
        "\n",
        "                detected_objects.append({\n",
        "                    \"label\": label_name,\n",
        "                    \"score\": float(score),\n",
        "                    \"box\": [int(x_min), int(y_min), int(x_max), int(y_max)]\n",
        "                })\n",
        "\n",
        "        output_filename   = os.path.basename(image_path).split('.')[0] + \"_detected.jpg\"\n",
        "        output_image_path = os.path.join(\"/content/\", output_filename)\n",
        "        img_orig.save(output_image_path)\n",
        "        print(f\"התמונה עם הזיהויים נשמרה ב: {output_image_path}\")\n",
        "\n",
        "        return detected_objects\n",
        "\n",
        "    # בודקים אם יש תמונות בסט הוולידציה\n",
        "    if dataset_val.image_ids:\n",
        "        # בוחר תמונה אקראית במקום הראשונה\n",
        "        random_idx = np.random.randint(0, len(dataset_val.image_ids))\n",
        "        example_image_base_name = dataset_val.image_ids[random_idx]\n",
        "        example_image_path = None\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:\n",
        "            temp_path = os.path.join(ROOT_DIR_TEST_IMAGES, example_image_base_name + ext)\n",
        "            if os.path.exists(temp_path):\n",
        "                example_image_path = temp_path\n",
        "                break\n",
        "\n",
        "        if example_image_path:\n",
        "            print(f\"מבצע הסקה על התמונה: {example_image_path}\")\n",
        "            detections = visualize_and_infer(model, example_image_path, CLASS_MAP, score_threshold=0.7)\n",
        "            if detections:\n",
        "                print(\"אובייקטים שזוהו:\")\n",
        "                for det in detections:\n",
        "                    print(f\"    מחלקה: {det['label']}, ציון: {det['score']:.2f}, תיבה: {det['box']}\")\n",
        "            else:\n",
        "                print(\"לא זוהו אובייקטים בסף הציון הנתון.\")\n",
        "        else:\n",
        "            print(\"שגיאה: לא נמצאה תמונה לדוגמה בתיקיית הוולידציה.\")\n",
        "    else:\n",
        "        print(\"אין תמונות בסט הוולידציה לביצוע הסקה.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxIOajHr2Ds_",
        "outputId": "507add72-da49-4f82-9df1-c83ac042a134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "משתמש ב- DEVICE: cuda\n",
            "טוען נתוני אימון...\n",
            "בתיקייה /content/final_burn_dataset/train/train_images: סה\"כ תמונות וביאורים נטענו בהצלחה: 981\n",
            "טוען נתוני בדיקה...\n",
            "בתיקייה /content/final_burn_dataset/test/test_images: סה\"כ תמונות וביאורים נטענו בהצלחה: 246\n",
            "יוצר מודל...\n",
            "\n",
            "---- אפוק 1 ----\n",
            "Epoch: 1, Iteration: 0/246, Loss: 2.0309\n",
            "Epoch: 1, Iteration: 10/246, Loss: 0.2552\n",
            "Epoch: 1, Iteration: 20/246, Loss: 0.3470\n",
            "Epoch: 1, Iteration: 30/246, Loss: 0.6059\n",
            "Epoch: 1, Iteration: 40/246, Loss: 0.2361\n",
            "Epoch: 1, Iteration: 50/246, Loss: 0.2754\n",
            "Epoch: 1, Iteration: 60/246, Loss: 0.3194\n",
            "Epoch: 1, Iteration: 70/246, Loss: 0.3210\n",
            "Epoch: 1, Iteration: 80/246, Loss: 0.1892\n",
            "Epoch: 1, Iteration: 90/246, Loss: 0.3121\n",
            "Epoch: 1, Iteration: 100/246, Loss: 0.4975\n",
            "Epoch: 1, Iteration: 110/246, Loss: 0.4148\n",
            "Epoch: 1, Iteration: 120/246, Loss: 0.3224\n",
            "Epoch: 1, Iteration: 130/246, Loss: 0.2594\n",
            "Epoch: 1, Iteration: 140/246, Loss: 0.4143\n",
            "Epoch: 1, Iteration: 150/246, Loss: 0.2326\n",
            "Epoch: 1, Iteration: 160/246, Loss: 0.3330\n",
            "Epoch: 1, Iteration: 170/246, Loss: 0.4126\n",
            "Epoch: 1, Iteration: 180/246, Loss: 0.3738\n",
            "Epoch: 1, Iteration: 190/246, Loss: 0.4448\n",
            "Epoch: 1, Iteration: 200/246, Loss: 0.4051\n",
            "Epoch: 1, Iteration: 210/246, Loss: 0.4275\n",
            "Epoch: 1, Iteration: 220/246, Loss: 0.3265\n",
            "Epoch: 1, Iteration: 230/246, Loss: 0.3223\n",
            "Epoch: 1, Iteration: 240/246, Loss: 0.3998\n",
            "איבוד באימון (Epoch 1): 0.3779\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.5178\n",
            "Eval Batch 50/62, Loss: 0.7154\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.4333\n",
            "איבוד ולידציה (Epoch 1): 0.4333\n",
            "שומר מודל טוב יותר! איבוד ולידציה ירד מ-inf ל-0.4333\n",
            "\n",
            "---- אפוק 2 ----\n",
            "Epoch: 2, Iteration: 0/246, Loss: 0.4234\n",
            "Epoch: 2, Iteration: 10/246, Loss: 0.3885\n",
            "Epoch: 2, Iteration: 20/246, Loss: 0.5787\n",
            "Epoch: 2, Iteration: 30/246, Loss: 0.3607\n",
            "Epoch: 2, Iteration: 40/246, Loss: 0.4298\n",
            "Epoch: 2, Iteration: 50/246, Loss: 0.2820\n",
            "Epoch: 2, Iteration: 60/246, Loss: 0.3072\n",
            "Epoch: 2, Iteration: 70/246, Loss: 0.2025\n",
            "Epoch: 2, Iteration: 80/246, Loss: 0.2374\n",
            "Epoch: 2, Iteration: 90/246, Loss: 0.3037\n",
            "Epoch: 2, Iteration: 100/246, Loss: 0.2764\n",
            "Epoch: 2, Iteration: 110/246, Loss: 0.2964\n",
            "Epoch: 2, Iteration: 120/246, Loss: 0.4596\n",
            "Epoch: 2, Iteration: 130/246, Loss: 0.3096\n",
            "Epoch: 2, Iteration: 140/246, Loss: 0.2197\n",
            "Epoch: 2, Iteration: 150/246, Loss: 0.5048\n",
            "Epoch: 2, Iteration: 160/246, Loss: 0.2660\n",
            "Epoch: 2, Iteration: 170/246, Loss: 0.4811\n",
            "Epoch: 2, Iteration: 180/246, Loss: 0.3264\n",
            "Epoch: 2, Iteration: 190/246, Loss: 0.1572\n",
            "Epoch: 2, Iteration: 200/246, Loss: 0.2911\n",
            "Epoch: 2, Iteration: 210/246, Loss: 0.5019\n",
            "Epoch: 2, Iteration: 220/246, Loss: 0.2717\n",
            "Epoch: 2, Iteration: 230/246, Loss: 0.2999\n",
            "Epoch: 2, Iteration: 240/246, Loss: 0.3914\n",
            "איבוד באימון (Epoch 2): 0.3642\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.4399\n",
            "Eval Batch 50/62, Loss: 0.6044\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.3890\n",
            "איבוד ולידציה (Epoch 2): 0.3890\n",
            "שומר מודל טוב יותר! איבוד ולידציה ירד מ-0.4333 ל-0.3890\n",
            "\n",
            "---- אפוק 3 ----\n",
            "Epoch: 3, Iteration: 0/246, Loss: 0.3282\n",
            "Epoch: 3, Iteration: 10/246, Loss: 0.4220\n",
            "Epoch: 3, Iteration: 20/246, Loss: 0.4388\n",
            "Epoch: 3, Iteration: 30/246, Loss: 0.3744\n",
            "Epoch: 3, Iteration: 40/246, Loss: 0.3577\n",
            "Epoch: 3, Iteration: 50/246, Loss: 0.3830\n",
            "Epoch: 3, Iteration: 60/246, Loss: 0.4739\n",
            "Epoch: 3, Iteration: 70/246, Loss: 0.4625\n",
            "Epoch: 3, Iteration: 80/246, Loss: 0.3202\n",
            "Epoch: 3, Iteration: 90/246, Loss: 0.5904\n",
            "Epoch: 3, Iteration: 100/246, Loss: 0.4799\n",
            "Epoch: 3, Iteration: 110/246, Loss: 0.3242\n",
            "Epoch: 3, Iteration: 120/246, Loss: 0.3643\n",
            "Epoch: 3, Iteration: 130/246, Loss: 0.3267\n",
            "Epoch: 3, Iteration: 140/246, Loss: 0.3769\n",
            "Epoch: 3, Iteration: 150/246, Loss: 0.3257\n",
            "Epoch: 3, Iteration: 160/246, Loss: 0.5346\n",
            "Epoch: 3, Iteration: 170/246, Loss: 0.2886\n",
            "Epoch: 3, Iteration: 180/246, Loss: 0.2912\n",
            "Epoch: 3, Iteration: 190/246, Loss: 0.3944\n",
            "Epoch: 3, Iteration: 200/246, Loss: 0.1984\n",
            "Epoch: 3, Iteration: 210/246, Loss: 0.4537\n",
            "Epoch: 3, Iteration: 220/246, Loss: 0.3240\n",
            "Epoch: 3, Iteration: 230/246, Loss: 0.3130\n",
            "Epoch: 3, Iteration: 240/246, Loss: 0.4176\n",
            "איבוד באימון (Epoch 3): 0.3588\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.3899\n",
            "Eval Batch 50/62, Loss: 0.5971\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.3998\n",
            "איבוד ולידציה (Epoch 3): 0.3998\n",
            "EarlyStopping counter: 1 מתוך 5\n",
            "\n",
            "---- אפוק 4 ----\n",
            "Epoch: 4, Iteration: 0/246, Loss: 0.4595\n",
            "Epoch: 4, Iteration: 10/246, Loss: 0.5869\n",
            "Epoch: 4, Iteration: 20/246, Loss: 0.3581\n",
            "Epoch: 4, Iteration: 30/246, Loss: 0.2051\n",
            "Epoch: 4, Iteration: 40/246, Loss: 0.3739\n",
            "Epoch: 4, Iteration: 50/246, Loss: 0.3895\n",
            "Epoch: 4, Iteration: 60/246, Loss: 0.4818\n",
            "Epoch: 4, Iteration: 70/246, Loss: 0.2858\n",
            "Epoch: 4, Iteration: 80/246, Loss: 0.1932\n",
            "Epoch: 4, Iteration: 90/246, Loss: 0.2202\n",
            "Epoch: 4, Iteration: 100/246, Loss: 0.7068\n",
            "Epoch: 4, Iteration: 110/246, Loss: 0.3705\n",
            "Epoch: 4, Iteration: 120/246, Loss: 0.4974\n",
            "Epoch: 4, Iteration: 130/246, Loss: 0.2910\n",
            "Epoch: 4, Iteration: 140/246, Loss: 0.2965\n",
            "Epoch: 4, Iteration: 150/246, Loss: 0.2857\n",
            "Epoch: 4, Iteration: 160/246, Loss: 0.2814\n",
            "Epoch: 4, Iteration: 170/246, Loss: 0.3808\n",
            "Epoch: 4, Iteration: 180/246, Loss: 0.3634\n",
            "Epoch: 4, Iteration: 190/246, Loss: 0.3033\n",
            "Epoch: 4, Iteration: 200/246, Loss: 0.3900\n",
            "Epoch: 4, Iteration: 210/246, Loss: 0.3043\n",
            "Epoch: 4, Iteration: 220/246, Loss: 0.5107\n",
            "Epoch: 4, Iteration: 230/246, Loss: 0.2018\n",
            "Epoch: 4, Iteration: 240/246, Loss: 0.4193\n",
            "איבוד באימון (Epoch 4): 0.3508\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.3875\n",
            "Eval Batch 50/62, Loss: 0.6321\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.3814\n",
            "איבוד ולידציה (Epoch 4): 0.3814\n",
            "שומר מודל טוב יותר! איבוד ולידציה ירד מ-0.3890 ל-0.3814\n",
            "\n",
            "---- אפוק 5 ----\n",
            "Epoch: 5, Iteration: 0/246, Loss: 0.2470\n",
            "Epoch: 5, Iteration: 10/246, Loss: 0.5460\n",
            "Epoch: 5, Iteration: 20/246, Loss: 0.2441\n",
            "Epoch: 5, Iteration: 30/246, Loss: 0.2535\n",
            "Epoch: 5, Iteration: 40/246, Loss: 0.4278\n",
            "Epoch: 5, Iteration: 50/246, Loss: 0.2708\n",
            "Epoch: 5, Iteration: 60/246, Loss: 0.6191\n",
            "Epoch: 5, Iteration: 70/246, Loss: 0.4649\n",
            "Epoch: 5, Iteration: 80/246, Loss: 0.3877\n",
            "Epoch: 5, Iteration: 90/246, Loss: 0.3349\n",
            "Epoch: 5, Iteration: 100/246, Loss: 0.3300\n",
            "Epoch: 5, Iteration: 110/246, Loss: 0.3095\n",
            "Epoch: 5, Iteration: 120/246, Loss: 0.2588\n",
            "Epoch: 5, Iteration: 130/246, Loss: 0.4155\n",
            "Epoch: 5, Iteration: 140/246, Loss: 0.3637\n",
            "Epoch: 5, Iteration: 150/246, Loss: 0.4951\n",
            "Epoch: 5, Iteration: 160/246, Loss: 0.3513\n",
            "Epoch: 5, Iteration: 170/246, Loss: 0.3428\n",
            "Epoch: 5, Iteration: 180/246, Loss: 0.2354\n",
            "Epoch: 5, Iteration: 190/246, Loss: 0.7829\n",
            "Epoch: 5, Iteration: 200/246, Loss: 0.2451\n",
            "Epoch: 5, Iteration: 210/246, Loss: 0.2734\n",
            "Epoch: 5, Iteration: 220/246, Loss: 0.3140\n",
            "Epoch: 5, Iteration: 230/246, Loss: 0.2249\n",
            "Epoch: 5, Iteration: 240/246, Loss: 0.5863\n",
            "איבוד באימון (Epoch 5): 0.3507\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.3900\n",
            "Eval Batch 50/62, Loss: 0.6028\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.3723\n",
            "איבוד ולידציה (Epoch 5): 0.3723\n",
            "שומר מודל טוב יותר! איבוד ולידציה ירד מ-0.3814 ל-0.3723\n",
            "\n",
            "---- אפוק 6 ----\n",
            "Epoch: 6, Iteration: 0/246, Loss: 0.2491\n",
            "Epoch: 6, Iteration: 10/246, Loss: 0.3413\n",
            "Epoch: 6, Iteration: 20/246, Loss: 0.2629\n",
            "Epoch: 6, Iteration: 30/246, Loss: 0.3986\n",
            "Epoch: 6, Iteration: 40/246, Loss: 0.3564\n",
            "Epoch: 6, Iteration: 50/246, Loss: 0.3641\n",
            "Epoch: 6, Iteration: 60/246, Loss: 0.5112\n",
            "Epoch: 6, Iteration: 70/246, Loss: 0.3553\n",
            "Epoch: 6, Iteration: 80/246, Loss: 0.5456\n",
            "Epoch: 6, Iteration: 90/246, Loss: 0.2456\n",
            "Epoch: 6, Iteration: 100/246, Loss: 0.3338\n",
            "Epoch: 6, Iteration: 110/246, Loss: 0.4159\n",
            "Epoch: 6, Iteration: 120/246, Loss: 0.7624\n",
            "Epoch: 6, Iteration: 130/246, Loss: 0.2910\n",
            "Epoch: 6, Iteration: 140/246, Loss: 0.4889\n",
            "Epoch: 6, Iteration: 150/246, Loss: 0.1874\n",
            "Epoch: 6, Iteration: 160/246, Loss: 0.2555\n",
            "Epoch: 6, Iteration: 170/246, Loss: 0.3731\n",
            "Epoch: 6, Iteration: 180/246, Loss: 0.4154\n",
            "Epoch: 6, Iteration: 190/246, Loss: 0.3462\n",
            "Epoch: 6, Iteration: 200/246, Loss: 0.2533\n",
            "Epoch: 6, Iteration: 210/246, Loss: 0.2516\n",
            "Epoch: 6, Iteration: 220/246, Loss: 0.5830\n",
            "Epoch: 6, Iteration: 230/246, Loss: 0.3170\n",
            "Epoch: 6, Iteration: 240/246, Loss: 0.3120\n",
            "איבוד באימון (Epoch 6): 0.3499\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.3716\n",
            "Eval Batch 50/62, Loss: 0.5947\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.3720\n",
            "איבוד ולידציה (Epoch 6): 0.3720\n",
            "שומר מודל טוב יותר! איבוד ולידציה ירד מ-0.3723 ל-0.3720\n",
            "EarlyStopping counter: 1 מתוך 5\n",
            "\n",
            "---- אפוק 7 ----\n",
            "Epoch: 7, Iteration: 0/246, Loss: 0.2252\n",
            "Epoch: 7, Iteration: 10/246, Loss: 0.2329\n",
            "Epoch: 7, Iteration: 20/246, Loss: 0.3099\n",
            "Epoch: 7, Iteration: 30/246, Loss: 0.2680\n",
            "Epoch: 7, Iteration: 40/246, Loss: 0.4126\n",
            "Epoch: 7, Iteration: 50/246, Loss: 0.2095\n",
            "Epoch: 7, Iteration: 60/246, Loss: 0.7041\n",
            "Epoch: 7, Iteration: 70/246, Loss: 0.1873\n",
            "Epoch: 7, Iteration: 80/246, Loss: 0.2814\n",
            "Epoch: 7, Iteration: 90/246, Loss: 0.2730\n",
            "Epoch: 7, Iteration: 100/246, Loss: 0.3902\n",
            "Epoch: 7, Iteration: 110/246, Loss: 0.1972\n",
            "Epoch: 7, Iteration: 120/246, Loss: 0.4204\n",
            "Epoch: 7, Iteration: 130/246, Loss: 0.5679\n",
            "Epoch: 7, Iteration: 140/246, Loss: 0.2948\n",
            "Epoch: 7, Iteration: 150/246, Loss: 0.2535\n",
            "Epoch: 7, Iteration: 160/246, Loss: 0.3215\n",
            "Epoch: 7, Iteration: 170/246, Loss: 0.3465\n",
            "Epoch: 7, Iteration: 180/246, Loss: 0.4087\n",
            "Epoch: 7, Iteration: 190/246, Loss: 0.3931\n",
            "Epoch: 7, Iteration: 200/246, Loss: 0.3746\n",
            "Epoch: 7, Iteration: 210/246, Loss: 0.3393\n",
            "Epoch: 7, Iteration: 220/246, Loss: 0.5691\n",
            "Epoch: 7, Iteration: 230/246, Loss: 0.3691\n",
            "Epoch: 7, Iteration: 240/246, Loss: 0.4184\n",
            "איבוד באימון (Epoch 7): 0.3432\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.3785\n",
            "Eval Batch 50/62, Loss: 0.5934\n",
            "הערכה בסיסית הושלמה. ממוצע הפסד ולידציה: 0.3733\n",
            "איבוד ולידציה (Epoch 7): 0.3733\n",
            "EarlyStopping counter: 2 מתוך 5\n",
            "\n",
            "---- אפוק 8 ----\n",
            "Epoch: 8, Iteration: 0/246, Loss: 0.3296\n",
            "Epoch: 8, Iteration: 10/246, Loss: 0.2946\n",
            "Epoch: 8, Iteration: 20/246, Loss: 0.3036\n",
            "Epoch: 8, Iteration: 30/246, Loss: 0.3286\n",
            "Epoch: 8, Iteration: 40/246, Loss: 0.2640\n",
            "Epoch: 8, Iteration: 50/246, Loss: 0.2891\n",
            "Epoch: 8, Iteration: 60/246, Loss: 0.2534\n",
            "Epoch: 8, Iteration: 70/246, Loss: 0.3945\n",
            "Epoch: 8, Iteration: 80/246, Loss: 0.5799\n",
            "Epoch: 8, Iteration: 90/246, Loss: 0.2597\n",
            "Epoch: 8, Iteration: 100/246, Loss: 0.5661\n",
            "Epoch: 8, Iteration: 110/246, Loss: 0.4691\n",
            "Epoch: 8, Iteration: 120/246, Loss: 0.3342\n",
            "Epoch: 8, Iteration: 130/246, Loss: 0.2582\n",
            "Epoch: 8, Iteration: 140/246, Loss: 0.3749\n",
            "Epoch: 8, Iteration: 150/246, Loss: 0.3404\n",
            "Epoch: 8, Iteration: 160/246, Loss: 0.2552\n",
            "Epoch: 8, Iteration: 170/246, Loss: 0.3324\n",
            "Epoch: 8, Iteration: 180/246, Loss: 0.4061\n",
            "Epoch: 8, Iteration: 190/246, Loss: 0.3112\n",
            "Epoch: 8, Iteration: 200/246, Loss: 0.2810\n",
            "Epoch: 8, Iteration: 210/246, Loss: 0.1458\n",
            "Epoch: 8, Iteration: 220/246, Loss: 0.2283\n",
            "Epoch: 8, Iteration: 230/246, Loss: 0.2629\n",
            "Epoch: 8, Iteration: 240/246, Loss: 0.4022\n",
            "איבוד באימון (Epoch 8): 0.3455\n",
            "מבצע הערכה על סט הבדיקה...\n",
            "Eval Batch 0/62, Loss: 0.3686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/best_fasterrcnn_model.pth')\n"
      ],
      "metadata": {
        "id": "Lp-IzZQ78dyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9ba810e-4962-4ec4-ba08-9ee631a5ef84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7bf47991-ea0e-4baf-90fe-8171949ea7a5\", \"best_fasterrcnn_model.pth\", 165772478)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "המודל הורד בהצלחה למחשב שלך.\n"
          ]
        }
      ]
    }
  ]
}